<style>
  .timeline {
    position: relative;
    max-width: 900px;
    margin: 2em auto;
  }

  .timeline::after {
    content: '';
    position: absolute;
    width: 6px;
    background-color: #009688;
    top: 0;
    bottom: 0;
    left: 50%;
    margin-left: -3px;
  }

  .container {
    padding: 10px 40px;
    position: relative;
    background-color: inherit;
    width: 50%;
  }

  .container::after {
    content: '';
    position: absolute;
    width: 25px;
    height: 25px;
    right: -17px;
    background-color: white;
    border: 4px solid #009688;
    top: 15px;
    border-radius: 50%;
    z-index: 1;
  }

  .left {
    left: 0;
  }

  .right {
    left: 50%;
  }

  .left::before {
    content: " ";
    height: 0;
    position: absolute;
    top: 22px;
    width: 0;
    z-index: 1;
    right: 30px;
    left: auto;
    border: medium solid rgba(255, 255, 255, 0.5);
    border-width: 10px 0 10px 10px;
    border-color: transparent transparent transparent rgba(255, 255, 255, 0.5);
  }

  .right::before {
    content: " ";
    height: 0;
    position: absolute;
    top: 22px;
    width: 0;
    z-index: 1;
    left: 30px;
    border: medium solid rgba(255, 255, 255, 0.5);
    border-width: 10px 10px 10px 0;
    border-color: transparent rgba(255, 255, 255, 0.5) transparent transparent;
  }

  .right::after {
    left: -16px;
  }

  .content {
    padding: 20px 30px;
    background-color: #f5f5f5;
    position: relative;
    border-radius: 6px;
    border-left: 4px solid #009688;
  }

  .content h3 {
    margin: 0 0 10px 0;
    color: #009688;
    font-size: 1.2em;
  }

  .content p {
    margin: 0;
    font-size: 0.95em;
    color: #666;
  }

  .content a {
    color: #009688;
    text-decoration: none;
    font-weight: 500;
  }

  .content a:hover {
    text-decoration: underline;
  }

  .year {
    font-weight: bold;
    color: #333;
    font-size: 1.1em;
  }

  .badge {
    display: inline-block;
    background-color: #e0f2f1;
    color: #00796b;
    padding: 3px 8px;
    border-radius: 12px;
    font-size: 0.85em;
    margin-right: 5px;
    margin-top: 5px;
  }

  @media screen and (max-width: 600px) {
    .timeline::after {
      left: 31px;
    }

    .container {
      width: 100%;
      padding-left: 70px;
      padding-right: 25px;
    }

    .container::before {
      left: 60px;
      border: medium solid rgba(255, 255, 255, 0.5);
      border-width: 10px 10px 10px 0;
      border-color: transparent rgba(255, 255, 255, 0.5) transparent transparent;
    }

    .left::after, .right::after {
      left: 15px;
    }

    .right {
      left: 0%;
    }
  }
</style>

<div class="timeline">
  <div class="container left">
    <div class="content">
      <h3><span class="year">2020</span> Bachelor's Graduation</h3>
      <p>Completed BSc in Computer Engineering from Iran University of Science and Technology (IUST) with focus on machine learning and algorithms.</p>
      <span class="badge">üéì Degree</span>
    </div>
  </div>

  <div class="container right">
    <div class="content">
      <h3><span class="year">2021</span> Master's at Sharif</h3>
      <p>Began MSc in Computer Engineering at Sharif University. Started research on AI safety, trustworthy systems, and large language model security.</p>
      <span class="badge">üî¨ Research</span>
    </div>
  </div>

  <div class="container left">
    <div class="content">
      <h3><span class="year">2023</span> Backdoor Detection Breakthrough</h3>
      <p>Published groundbreaking research on <strong>BAIT: Backdoor Scanning by Inverting Attack Target</strong> - a novel approach to detecting backdoor attacks in LLMs. Presented at major AI conferences and venues.</p>
      <span class="badge">üìù Published</span>
      <span class="badge">üèÜ Recognition</span>
    </div>
  </div>

  <div class="container right">
    <div class="content">
      <h3><span class="year">2024</span> Active Contributor & Researcher</h3>
      <p>Advanced research in LLM security, adversarial robustness, and trustworthy AI. Published multiple papers on model defense mechanisms. Collaborated with international AI safety researchers. <a href="https://scholar.google.com/citations?user=ukjmhFwAAAAJ">Track citations on Google Scholar</a>.</p>
      <span class="badge">üìä 2024 Papers</span>
      <span class="badge">ü§ù Collaborations</span>
    </div>
  </div>

  <div class="container left">
    <div class="content">
      <h3><span class="year">2025</span> Ongoing & Impact</h3>
      <p>Continuing advanced research in AI safety and LLM robustness. Contributing to open-source security tools. <a href="https://github.com/amirrezavishteh">Check GitHub for latest implementations</a>. Open to research collaborations and consulting on AI security.</p>
      <span class="badge">üíª Open Source</span>
      <span class="badge">üîê Security Focus</span>
    </div>
  </div>
</div>
